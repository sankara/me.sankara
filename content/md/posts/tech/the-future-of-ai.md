{:title "The Future of AI and Space Sci-Fi"
:layout :post
:date "2021-06-26"
:tags ["blog" "tech"]
:author "Sankara"}

There's an entire range of depictions when it comes to AI in space travel themed science fiction movies and TV shows. Hal, for example, is a conscious AI - for some definition of consciousness. While this is a wonderful plot device and something tech visionaries have been saying is right around the corner, it's not how I view AI at all.  

I think the show Expanse got it just right. All the ships and stations are loded with AIs but you'd never even notice them. It's subtle. The AI does the job and get out of the way. Take the example of intercepting missiles with PDCs or firing a rail gun, it's not a simple or trivial process and the show goes to great lengths to make that clear as well. There are a huge variety of parameters to consider to keep the ship stable when it's firing its rail gun. This is space and Newton's third law is a bitch. Counteracting forces - via thrusters - are required in extreme precision to keep the ship from spinning or moving in any of the 3D space. 

Similarly, the countless other things to monitor in a ship and adjust automatically is the only way space travel would be possible. A very minor angle shift could mean the difference between reaching two entirely different planets and nothing's ever staionery in space. 

I also found it cool the way the crew interacts with the ship is depicted - a mix of voice commands and gestures *and* an AI that can interpret what they mean.  

My point is that none of this requires an AGI - Artificial General Intelligence - just AI would do. If we could replicate, what evolution has taught animals to do that in itself would be nothing short of a mirace.  Think abkut it - a hummingbird with the brain the size of a pea, can flap its wings at 53 times a second, maintain near perfect stillness, dodge obstacles, seek out food and recognise what is good and what is not, identify danger, identify a mate and on and on. 

A hummingbird is not what we typically think of when we think intelligence or comsciousness. But it's precisely this type of intelligence that's going to be useful for humans and I don't see any reason why we'd first solve AGI before building these AIs.